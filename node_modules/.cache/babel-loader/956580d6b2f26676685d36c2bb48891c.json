{"ast":null,"code":"import _classCallCheck from \"D:\\\\Senior Project\\\\RealTimeSignDetection\\\\ReactComputerVisionTemplate\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/classCallCheck\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nexport var DepthwiseConvPacked2DProgram = function DepthwiseConvPacked2DProgram(convInfo) {\n  var addBias = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  var activation = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n  var hasPreluActivation = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  var hasLeakyReluAlpha = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n\n  _classCallCheck(this, DepthwiseConvPacked2DProgram);\n\n  this.variableNames = ['x', 'W'];\n  this.packedInputs = true;\n  this.packedOutput = true;\n  this.outputShape = convInfo.outShape;\n  var channelMul = convInfo.outChannels / convInfo.inChannels;\n  var xNumRows = convInfo.inHeight;\n  var xNumCols = convInfo.inWidth;\n  var padTop = convInfo.padInfo.top;\n  var padLeft = convInfo.padInfo.left;\n  var strideHeight = convInfo.strideHeight;\n  var strideWidth = convInfo.strideWidth;\n  var dilationHeight = convInfo.dilationHeight;\n  var dilationWidth = convInfo.dilationWidth;\n  var filterHeight = convInfo.filterHeight;\n  var filterWidth = convInfo.filterWidth;\n  var texelsAcross = filterWidth;\n  var mainLoop = \"\\n      int xR; int xC; int xCOffset;\\n      vec4 wTexel; vec4 previous; vec4 final;\";\n\n  for (var c = 0; c < filterWidth; c++) {\n    mainLoop += \"\\n          vec4 xTexelC\".concat(c * 2, \";\\n          int xTexelC\").concat(c * 2, \"Ready;\\n          vec4 xC\").concat(c, \";\");\n  }\n  /**\n   * This vectorized implementation works by gathering the values needed for\n   * each output channel's dot product into vec4's and then multiplying them\n   * all together (this happens in the final double for-loop below). Most of\n   * the main loop consists of constructing these vec4's with the minimum\n   * number of texture2D calls, which means making use of all four returned\n   * values from a texture2D call at once.\n   */\n\n\n  for (var r = 0; r < filterHeight; r++) {\n    for (var _c = 0; _c < filterWidth; _c++) {\n      mainLoop += \"\\n          xTexelC\".concat(_c * 2, \" = vec4(0.0);\\n          xTexelC\").concat(_c * 2, \"Ready = 0;\\n          xC\").concat(_c, \" = vec4(0.0);\");\n    }\n\n    mainLoop += \"\\n        xR = xRCorner + \".concat(r * dilationHeight, \";\\n        if (xR >=0 && xR < \").concat(xNumRows, \") {\\n      \");\n\n    for (var texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n      var colIndex = texelC * 2;\n\n      var _c2 = colIndex * dilationWidth;\n\n      mainLoop += \"\\n          xC = xCCorner + \".concat(_c2, \";\\n          \");\n\n      if (strideWidth === 1) {\n        if (colIndex < filterWidth) {\n          // If padding is odd, the outer texels have to be composed.\n          if (padLeft % 2 === 1) {\n            // TODO: Ensure vec4 previous does not result in redundant sample,\n            // and avoid setting xTexelRC's that exceed the boundary in the\n            // first place rather than resetting them to vec4(0)).\n            // To compute xCOffset:\n            // - If padding is odd, we must add 1 to ensure we ask for an\n            // even-numbered row.\n            // - We subtract 2 to access the previous texel.\n            mainLoop += \"\\n                xCOffset = xC + 1;\\n                if (xCOffset >= 0 && xCOffset < \".concat(xNumCols, \" && xTexelC\").concat(_c2, \"Ready == 0) {\\n                  xTexelC\").concat(_c2, \" = getX(batch, xR, xCOffset, d1);\\n\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(_c2, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_c2, \"Ready = 1;\\n                }\\n              \"); // This texel has been read in previous iteration if the dilation\n            // is 1.\n\n            if (dilationWidth === 1 && _c2 > 0) {\n              mainLoop += \"\\n                xC\".concat(colIndex, \" = vec4(xTexelC\").concat(_c2 - 2, \".zw, xTexelC\").concat(_c2, \".xy);\\n                \");\n            } else {\n              mainLoop += \"\\n                  xCOffset = xC + 1 - 2;\\n\\n                  if (xCOffset >= 0 && xCOffset < \".concat(xNumCols, \") {\\n                    previous = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                      previous.zw = vec2(0.0);\\n                    }\\n\\n                    xC\").concat(colIndex, \" = vec4(previous.zw, xTexelC\").concat(_c2, \".xy);\\n                  } else {\\n                    xC\").concat(colIndex, \" = vec4(0.0, 0.0, xTexelC\").concat(_c2, \".xy);\\n                  }\\n                  \");\n            }\n          } else {\n            // Padding is even, so xRC corresponds to a single texel.\n            mainLoop += \"\\n                if (xC >= 0 && xC < \".concat(xNumCols, \" && xTexelC\").concat(_c2, \"Ready == 0) {\\n                  xTexelC\").concat(_c2, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(_c2, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_c2, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = xTexelC\").concat(_c2, \";\\n                \");\n          }\n\n          if (_c2 + 1 < filterWidth) {\n            // If dilation is even, the second entry should match the first\n            // (either both are composed or both are single samples). But if\n            // dilation is odd, then the second entry should be the opposite\n            // of the first (if the first is composed, the second is a single\n            // sample, and vice versa.)\n            var nextTexelOffset = padLeft % 2 === 0 ? util.nearestLargerEven(dilationWidth) : dilationWidth;\n\n            if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {\n              mainLoop += \"\\n                  xCOffset = xC + \".concat(padLeft % 2, \" + \").concat(nextTexelOffset, \";\\n\\n                  if (xCOffset >= 0 && xCOffset < \").concat(xNumCols, \" && xTexelC\").concat(_c2 + 2, \"Ready == 0) {\\n                    xTexelC\").concat(_c2 + 2, \" = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                      xTexelC\").concat(_c2 + 2, \".zw = vec2(0.0);\\n                    }\\n                    xTexelC\").concat(_c2 + 2, \"Ready = 1;\\n                  }\\n                  \"); // If dilation > 1 then the xRC's will not be able to share any\n              // values, so each xRC will require two unique calls to getX.\n\n              if (dilationWidth > 1) {\n                mainLoop += \"\\n                    xCOffset -= 2;\\n                    if (xCOffset >= 0 && xCOffset < \".concat(xNumCols, \" && xTexelC\").concat(_c2, \"Ready == 0) {\\n                      xTexelC\").concat(_c2, \" = getX(batch, xR, xCOffset, d1);\\n                      xTexelC\").concat(_c2, \"Ready = 1;\\n                    }\\n                    \");\n              }\n\n              mainLoop += \"\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(_c2, \".zw, xTexelC\").concat(_c2 + 2, \".xy);\\n                  \");\n            } else {\n              // If dilation is 1 and padding is odd, we have already read the\n              // texel when constructing the previous x value. Here we can\n              // simply skip the texture read.\n              if (nextTexelOffset === 1) {\n                mainLoop += \"\\n                    xC\".concat(colIndex + 1, \" = xTexelC\").concat(_c2, \";\\n                    \");\n              } else {\n                mainLoop += \"\\n                    xCOffset = xC + \".concat(nextTexelOffset, \";\\n\\n                    if (xCOffset >= 0 && xCOffset < \").concat(xNumCols, \" && xTexelC\").concat(_c2 + 2, \"Ready == 0) {\\n                      xTexelC\").concat(_c2 + 2, \" = getX(batch, xR, xCOffset, d1);\\n                      if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                        xTexelC\").concat(_c2 + 2, \".zw = vec2(0.0);\\n                      }\\n                      xTexelC\").concat(_c2 + 2, \"Ready = 1;\\n                    }\\n\\n                    xC\").concat(colIndex + 1, \" = xTexelC\").concat(_c2 + 2, \";\\n                    \");\n              }\n            }\n          }\n        }\n      } else {\n        // stride === 2\n        if (_c2 < filterWidth) {\n          // Depending on whether padLeft is even or odd, we want either the\n          // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n          // even, xC${colIndex +1} is simply the zw channels of texels we've\n          // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n          // need to come from the xy channels of a new texel, hence the `\n          // vec4\n          // final` initialized below.\n          if (padLeft % 2 === 1) {\n            mainLoop += \"\\n                xCOffset = xC + 1 - \".concat(strideWidth, \";\\n                if(xCOffset >= 0 && xCOffset < \").concat(xNumCols, \" && xTexelC\").concat(_c2, \"Ready == 0) {\\n                  xTexelC\").concat(_c2, \" = getX(batch, xR, xCOffset, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(_c2, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_c2, \"Ready = 1;\\n                }\\n\\n                if(xC + 1 >= 0 && xC + 1 < \").concat(xNumCols, \" && xTexelC\").concat(_c2 + 2, \"Ready == 0) {\\n                  xTexelC\").concat(_c2 + 2, \" = getX(batch, xR, xC + 1, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xC + 2 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(_c2 + 2, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_c2 + 2, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = vec4(xTexelC\").concat(_c2, \".zw, xTexelC\").concat(_c2 + 2, \".zw);\\n              \");\n\n            if (_c2 + 1 < filterWidth) {\n              mainLoop += \"\\n                  final = vec4(0.0);\\n                  xCOffset = xC + 1 + \".concat(strideWidth, \";\\n                  if(xCOffset >= 0 && xCOffset < \").concat(xNumCols, \") {\\n                    final = getX(batch, xR, xCOffset, d1);\\n                  }\\n                  xC\").concat(colIndex + 1, \" = vec4(xTexelC\").concat(_c2 + 2, \".xy, final.xy);\\n                \");\n            }\n          } else {\n            mainLoop += \"\\n                if(xC >= 0 && xC < \".concat(xNumCols, \" && xTexelC\").concat(_c2, \"Ready == 0) {\\n                  xTexelC\").concat(_c2, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(_c2, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(_c2, \"Ready = 1;\\n                }\\n\\n                xCOffset = xC + \").concat(strideWidth, \";\\n                if(xCOffset >= 0 && xCOffset < \").concat(xNumCols, \" && xTexelC\").concat(_c2 + 2, \"Ready == 0) {\\n                  xTexelC\").concat(_c2 + 2, \" = getX(batch, xR, xCOffset, d1);\\n                  if (xCOffset + 1 >= \").concat(xNumCols, \") {\\n                    xTexelC\").concat(_c2 + 2, \".zw = vec2(0.);\\n                  }\\n                  xTexelC\").concat(_c2 + 2, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = vec4(\\n                  xTexelC\").concat(_c2, \".xy, xTexelC\").concat(_c2 + 2, \".xy);\\n              \");\n\n            if (_c2 + 1 < filterWidth) {\n              mainLoop += \"\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(_c2, \".zw, xTexelC\").concat(_c2 + 2, \".zw);\\n                \");\n            }\n          }\n        }\n      } // localize the dotProd accumulation within the loop, the theory is for\n      // GPU with limited cache, accumulate sum across large amount of\n      // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n      // 50 variables)\n\n\n      if (colIndex < filterWidth) {\n        mainLoop += \"\\n            wTexel = getW(\".concat(r, \", \").concat(_c2, \", d1, q);\\n            dotProd += xC\").concat(colIndex, \" * vec4(wTexel.xz, wTexel.xz);\\n          \");\n\n        if (_c2 + 1 < filterWidth) {\n          mainLoop += \"\\n              wTexel = getW(\".concat(r, \", \").concat(_c2 + 1, \", d1, q);\\n              dotProd += xC\").concat(colIndex + 1, \" * vec4(wTexel.xz, wTexel.xz);\\n            \");\n        }\n      }\n    }\n\n    mainLoop += \"\\n        }\\n      \";\n  }\n\n  var activationSnippet = '',\n      applyActivationSnippet = '';\n\n  if (activation) {\n    if (hasPreluActivation) {\n      activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(activation, \"\\n        }\");\n    } else if (hasLeakyReluAlpha) {\n      activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(activation, \"\\n        }\");\n    } else {\n      activationSnippet = \"vec4 activation(vec4 x) {\\n          \".concat(activation, \"\\n        }\");\n    }\n\n    applyActivationSnippet = \"result = activation(result);\";\n  }\n\n  var addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n\n  if (addBias) {\n    this.variableNames.push('bias');\n  }\n\n  if (hasPreluActivation) {\n    this.variableNames.push('preluActivationWeights');\n  }\n\n  if (hasLeakyReluAlpha) {\n    this.variableNames.push('leakyreluAlpha');\n  }\n\n  this.userCode = \"\\n      \".concat(activationSnippet, \"\\n\\n      const ivec2 strides = ivec2(\").concat(strideHeight, \", \").concat(strideWidth, \");\\n      const ivec2 pads = ivec2(\").concat(padTop, \", \").concat(padLeft, \");\\n\\n      void main() {\\n\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \").concat(channelMul, \";\\n        int q = d2 - d1 * \").concat(channelMul, \";\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\\n        vec4 dotProd = vec4(0.000000000000001);\\n\\n        \").concat(mainLoop, \"\\n\\n        vec4 result = dotProd - vec4(0.000000000000001);\\n        \").concat(addBiasSnippet, \"\\n        \").concat(applyActivationSnippet, \"\\n        setOutput(result);\\n      }\\n    \");\n};","map":{"version":3,"sources":["../src/conv_packed_gpu_depthwise.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;;AAiBA,SAAsB,IAAtB,QAAiC,uBAAjC;AAIA,WAAa,4BAAb,GAOE,sCACI,QADJ,EAG6B;AAAA,MAFU,OAEV,uEAFoB,KAEpB;AAAA,MADzB,UACyB,uEADJ,IACI;AAAA,MADE,kBACF,uEADuB,KACvB;AAAA,MAAzB,iBAAyB,uEAAL,KAAK;;AAAA;;AAT7B,OAAA,aAAA,GAAgB,CAAC,GAAD,EAAM,GAAN,CAAhB;AACA,OAAA,YAAA,GAAe,IAAf;AACA,OAAA,YAAA,GAAe,IAAf;AAQE,OAAK,WAAL,GAAmB,QAAQ,CAAC,QAA5B;AACA,MAAM,UAAU,GAAG,QAAQ,CAAC,WAAT,GAAuB,QAAQ,CAAC,UAAnD;AACA,MAAM,QAAQ,GAAG,QAAQ,CAAC,QAA1B;AACA,MAAM,QAAQ,GAAG,QAAQ,CAAC,OAA1B;AACA,MAAM,MAAM,GAAG,QAAQ,CAAC,OAAT,CAAiB,GAAhC;AACA,MAAM,OAAO,GAAG,QAAQ,CAAC,OAAT,CAAiB,IAAjC;AACA,MAAM,YAAY,GAAG,QAAQ,CAAC,YAA9B;AACA,MAAM,WAAW,GAAG,QAAQ,CAAC,WAA7B;AACA,MAAM,cAAc,GAAG,QAAQ,CAAC,cAAhC;AACA,MAAM,aAAa,GAAG,QAAQ,CAAC,aAA/B;AACA,MAAM,YAAY,GAAG,QAAQ,CAAC,YAA9B;AACA,MAAM,WAAW,GAAG,QAAQ,CAAC,WAA7B;AACA,MAAM,YAAY,GAAG,WAArB;AAEA,MAAI,QAAQ,yFAAZ;;AAIA,OAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,WAApB,EAAiC,CAAC,EAAlC,EAAsC;AACpC,IAAA,QAAQ,sCACU,CAAC,GAAG,CADd,qCAES,CAAC,GAAG,CAFb,sCAGK,CAHL,MAAR;AAID;AAED;;;;;;;;;;AAQA,OAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,YAApB,EAAkC,CAAC,EAAnC,EAAuC;AACrC,SAAK,IAAI,EAAC,GAAG,CAAb,EAAgB,EAAC,GAAG,WAApB,EAAiC,EAAC,EAAlC,EAAsC;AACpC,MAAA,QAAQ,iCACG,EAAC,GAAG,CADP,6CAEG,EAAC,GAAG,CAFP,qCAGF,EAHE,kBAAR;AAID;;AACD,IAAA,QAAQ,wCACY,CAAC,GAAG,cADhB,2CAEe,QAFf,gBAAR;;AAKA,SAAK,IAAI,MAAM,GAAG,CAAlB,EAAqB,MAAM,GAAG,CAAC,YAAY,GAAG,CAAhB,IAAqB,CAAnD,EAAsD,MAAM,EAA5D,EAAgE;AAC9D,UAAM,QAAQ,GAAG,MAAM,GAAG,CAA1B;;AACA,UAAM,GAAC,GAAG,QAAQ,GAAG,aAArB;;AAEA,MAAA,QAAQ,0CACY,GADZ,kBAAR;;AAIA,UAAI,WAAW,KAAK,CAApB,EAAuB;AACrB,YAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B;AACA,cAAI,OAAO,GAAG,CAAV,KAAgB,CAApB,EAAuB;AACrB;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA,YAAA,QAAQ,oGAE4B,QAF5B,wBAGJ,GAHI,qDAIK,GAJL,wNAQkB,QARlB,6CASO,GATP,6EAWK,GAXL,kDAAR,CAVqB,CAwBrB;AACA;;AACA,gBAAI,aAAa,KAAK,CAAlB,IAAuB,GAAC,GAAG,CAA/B,EAAkC;AAChC,cAAA,QAAQ,kCACJ,QADI,4BACsB,GAAC,GAAG,CAD1B,yBAC0C,GAD1C,4BAAR;AAGD,aAJD,MAIO;AACL,cAAA,QAAQ,8GAG4B,QAH5B,+PAQkB,QARlB,iHAYA,QAZA,yCAYuC,GAZvC,sEAcA,QAdA,sCAcoC,GAdpC,mDAAR;AAiBD;AACF,WAjDD,MAiDO;AACL;AACA,YAAA,QAAQ,oDACgB,QADhB,wBACsC,GADtC,qDAEK,GAFL,0EAGY,QAHZ,6CAIO,GAJP,6EAMK,GANL,gEASF,QATE,uBASmB,GATnB,wBAAR;AAWD;;AAED,cAAI,GAAC,GAAG,CAAJ,GAAQ,WAAZ,EAAyB;AACvB;AACA;AACA;AACA;AACA;AAEA,gBAAM,eAAe,GAAG,OAAO,GAAG,CAAV,KAAgB,CAAhB,GACpB,IAAI,CAAC,iBAAL,CAAuB,aAAvB,CADoB,GAEpB,aAFJ;;AAIA,gBAAK,aAAa,GAAG,CAAhB,KAAsB,CAAtB,IAA2B,OAAO,GAAG,CAAV,KAAgB,CAA5C,IACC,aAAa,GAAG,CAAhB,KAAsB,CAAtB,IAA2B,OAAO,GAAG,CAAV,KAAgB,CADhD,EACoD;AAClD,cAAA,QAAQ,kDACY,OAAO,GAAG,CADtB,gBAC6B,eAD7B,oEAG4B,QAH5B,wBAIJ,GAAC,GAAG,CAJA,uDAKK,GAAC,GAAG,CALT,8NASkB,QATlB,+CAUO,GAAC,GAAG,CAVX,iFAYK,GAAC,GAAG,CAZT,wDAAR,CADkD,CAiBlD;AACA;;AACA,kBAAI,aAAa,GAAG,CAApB,EAAuB;AACrB,gBAAA,QAAQ,wGAE4B,QAF5B,wBAGJ,GAHI,yDAIK,GAJL,6EAKK,GALL,4DAAR;AAQD;;AAED,cAAA,QAAQ,oCACF,QAAQ,GAAG,CADT,4BAC4B,GAD5B,yBAC4C,GAAC,GAAG,CADhD,8BAAR;AAGD,aAlCD,MAkCO;AACL;AACA;AACA;AACA,kBAAI,eAAe,KAAK,CAAxB,EAA2B;AACzB,gBAAA,QAAQ,sCACF,QAAQ,GAAG,CADT,uBACuB,GADvB,4BAAR;AAGD,eAJD,MAIO;AACL,gBAAA,QAAQ,oDACY,eADZ,sEAG4B,QAH5B,wBAIJ,GAAC,GAAG,CAJA,yDAKK,GAAC,GAAG,CALT,0FAMkB,QANlB,iDAOO,GAAC,GAAG,CAPX,qFASK,GAAC,GAAG,CATT,wEAYF,QAAQ,GAAG,CAZT,uBAYuB,GAAC,GAAG,CAZ3B,4BAAR;AAcD;AACF;AACF;AACF;AACF,OA3ID,MA2IO;AAAG;AACR,YAAI,GAAC,GAAG,WAAR,EAAqB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAI,OAAO,GAAG,CAAV,KAAgB,CAApB,EAAuB;AACrB,YAAA,QAAQ,oDACgB,WADhB,+DAE2B,QAF3B,wBAGJ,GAHI,qDAIK,GAJL,sNAOkB,QAPlB,6CAQO,GARP,6EAUK,GAVL,yFAauB,QAbvB,wBAcJ,GAAC,GAAG,CAdA,qDAeK,GAAC,GAAG,CAfT,8MAkBY,QAlBZ,6CAmBO,GAAC,GAAG,CAnBX,6EAqBK,GAAC,GAAG,CArBT,gEAwBF,QAxBE,4BAwBwB,GAxBxB,yBAwBwC,GAAC,GAAG,CAxB5C,0BAAR;;AA2BA,gBAAI,GAAC,GAAG,CAAJ,GAAQ,WAAZ,EAAyB;AACvB,cAAA,QAAQ,4FAEgB,WAFhB,iEAG2B,QAH3B,uHAMF,QAAQ,GAAG,CANT,4BAM4B,GAAC,GAAG,CANhC,sCAAR;AAQD;AACF,WAtCD,MAsCO;AACL,YAAA,QAAQ,mDACe,QADf,wBACqC,GADrC,qDAEK,GAFL,0EAGY,QAHZ,6CAIO,GAJP,6EAMK,GANL,8EASY,WATZ,+DAU2B,QAV3B,wBAWJ,GAAC,GAAG,CAXA,qDAYK,GAAC,GAAG,CAZT,sFAakB,QAblB,6CAcO,GAAC,GAAG,CAdX,4EAgBK,GAAC,GAAG,CAhBT,gEAmBF,QAnBE,gDAoBK,GApBL,yBAoBqB,GAAC,GAAG,CApBzB,0BAAR;;AAuBA,gBAAI,GAAC,GAAG,CAAJ,GAAQ,WAAZ,EAAyB;AACvB,cAAA,QAAQ,oCACF,QAAQ,GAAG,CADT,4BAC4B,GAD5B,yBAC4C,GAAC,GAAG,CADhD,4BAAR;AAGD;AACF;AACF;AACF,OAjO6D,CAmO9D;AACA;AACA;AACA;;;AACA,UAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B,QAAA,QAAQ,0CACU,CADV,eACgB,GADhB,iDAES,QAFT,+CAAR;;AAKA,YAAI,GAAC,GAAG,CAAJ,GAAQ,WAAZ,EAAyB;AACvB,UAAA,QAAQ,4CACU,CADV,eACgB,GAAC,GAAG,CADpB,mDAES,QAAQ,GAAG,CAFpB,iDAAR;AAID;AACF;AACF;;AACD,IAAA,QAAQ,yBAAR;AAGD;;AAED,MAAI,iBAAiB,GAAG,EAAxB;AAAA,MAA4B,sBAAsB,GAAG,EAArD;;AACA,MAAI,UAAJ,EAAgB;AACd,QAAI,kBAAJ,EAAwB;AACtB,MAAA,iBAAiB,8GAEb,UAFa,gBAAjB;AAID,KALD,MAKO,IAAI,iBAAJ,EAAuB;AAC5B,MAAA,iBAAiB,sGAEb,UAFa,gBAAjB;AAID,KALM,MAKA;AACL,MAAA,iBAAiB,kDACb,UADa,gBAAjB;AAGD;;AAED,IAAA,sBAAsB,iCAAtB;AACD;;AAED,MAAM,cAAc,GAAG,OAAO,GAAG,iCAAH,GAAuC,EAArE;;AACA,MAAI,OAAJ,EAAa;AACX,SAAK,aAAL,CAAmB,IAAnB,CAAwB,MAAxB;AACD;;AAED,MAAI,kBAAJ,EAAwB;AACtB,SAAK,aAAL,CAAmB,IAAnB,CAAwB,wBAAxB;AACD;;AACD,MAAI,iBAAJ,EAAuB;AACrB,SAAK,aAAL,CAAmB,IAAnB,CAAwB,gBAAxB;AACD;;AAED,OAAK,QAAL,qBACI,iBADJ,mDAGgC,YAHhC,eAGiD,WAHjD,gDAI6B,MAJ7B,eAIwC,OAJxC,6NAYoB,UAZpB,0CAawB,UAbxB,4OAoBM,QApBN,mFAuBM,cAvBN,uBAwBM,sBAxBN;AA4BD,CA/WH","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\n\nimport {GPGPUProgram} from './gpgpu_math';\n\nexport class DepthwiseConvPacked2DProgram implements GPGPUProgram {\n  variableNames = ['x', 'W'];\n  packedInputs = true;\n  packedOutput = true;\n  outputShape: number[];\n  userCode: string;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: string = null, hasPreluActivation = false,\n      hasLeakyReluAlpha = false) {\n    this.outputShape = convInfo.outShape;\n    const channelMul = convInfo.outChannels / convInfo.inChannels;\n    const xNumRows = convInfo.inHeight;\n    const xNumCols = convInfo.inWidth;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const texelsAcross = filterWidth;\n\n    let mainLoop = `\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;`;\n\n    for (let c = 0; c < filterWidth; c++) {\n      mainLoop += `\n          vec4 xTexelC${c * 2};\n          int xTexelC${c * 2}Ready;\n          vec4 xC${c};`;\n    }\n\n    /**\n     * This vectorized implementation works by gathering the values needed for\n     * each output channel's dot product into vec4's and then multiplying them\n     * all together (this happens in the final double for-loop below). Most of\n     * the main loop consists of constructing these vec4's with the minimum\n     * number of texture2D calls, which means making use of all four returned\n     * values from a texture2D call at once.\n     */\n    for (let r = 0; r < filterHeight; r++) {\n      for (let c = 0; c < filterWidth; c++) {\n        mainLoop += `\n          xTexelC${c * 2} = vec4(0.0);\n          xTexelC${c * 2}Ready = 0;\n          xC${c} = vec4(0.0);`;\n      }\n      mainLoop += `\n        xR = xRCorner + ${r * dilationHeight};\n        if (xR >=0 && xR < ${xNumRows}) {\n      `;\n\n      for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n        const colIndex = texelC * 2;\n        const c = colIndex * dilationWidth;\n\n        mainLoop += `\n          xC = xCCorner + ${c};\n          `;\n\n        if (strideWidth === 1) {\n          if (colIndex < filterWidth) {\n            // If padding is odd, the outer texels have to be composed.\n            if (padLeft % 2 === 1) {\n              // TODO: Ensure vec4 previous does not result in redundant sample,\n              // and avoid setting xTexelRC's that exceed the boundary in the\n              // first place rather than resetting them to vec4(0)).\n\n              // To compute xCOffset:\n              // - If padding is odd, we must add 1 to ensure we ask for an\n              // even-numbered row.\n              // - We subtract 2 to access the previous texel.\n\n              mainLoop += `\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                  c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n              `;\n              // This texel has been read in previous iteration if the dilation\n              // is 1.\n              if (dilationWidth === 1 && c > 0) {\n                mainLoop += `\n                xC${colIndex} = vec4(xTexelC${c - 2}.zw, xTexelC${c}.xy);\n                `;\n              } else {\n                mainLoop += `\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < ${xNumCols}) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${xNumCols}) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${colIndex} = vec4(previous.zw, xTexelC${c}.xy);\n                  } else {\n                    xC${colIndex} = vec4(0.0, 0.0, xTexelC${c}.xy);\n                  }\n                  `;\n              }\n            } else {\n              // Padding is even, so xRC corresponds to a single texel.\n              mainLoop += `\n                if (xC >= 0 && xC < ${xNumCols} && xTexelC${c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n\n                xC${colIndex} = xTexelC${c};\n                `;\n            }\n\n            if (c + 1 < filterWidth) {\n              // If dilation is even, the second entry should match the first\n              // (either both are composed or both are single samples). But if\n              // dilation is odd, then the second entry should be the opposite\n              // of the first (if the first is composed, the second is a single\n              // sample, and vice versa.)\n\n              const nextTexelOffset = padLeft % 2 === 0 ?\n                  util.nearestLargerEven(dilationWidth) :\n                  dilationWidth;\n\n              if ((dilationWidth % 2 === 0 && padLeft % 2 === 1) ||\n                  (dilationWidth % 2 !== 0 && padLeft % 2 !== 1)) {\n                mainLoop += `\n                  xCOffset = xC + ${padLeft % 2} + ${nextTexelOffset};\n\n                  if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                    c + 2}Ready == 0) {\n                    xTexelC${c + 2} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${xNumCols}) {\n                      xTexelC${c + 2}.zw = vec2(0.0);\n                    }\n                    xTexelC${c + 2}Ready = 1;\n                  }\n                  `;\n\n                // If dilation > 1 then the xRC's will not be able to share any\n                // values, so each xRC will require two unique calls to getX.\n                if (dilationWidth > 1) {\n                  mainLoop += `\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                      c}Ready == 0) {\n                      xTexelC${c} = getX(batch, xR, xCOffset, d1);\n                      xTexelC${c}Ready = 1;\n                    }\n                    `;\n                }\n\n                mainLoop += `\n                  xC${colIndex + 1} = vec4(xTexelC${c}.zw, xTexelC${c + 2}.xy);\n                  `;\n              } else {\n                // If dilation is 1 and padding is odd, we have already read the\n                // texel when constructing the previous x value. Here we can\n                // simply skip the texture read.\n                if (nextTexelOffset === 1) {\n                  mainLoop += `\n                    xC${colIndex + 1} = xTexelC${c};\n                    `;\n                } else {\n                  mainLoop += `\n                    xCOffset = xC + ${nextTexelOffset};\n\n                    if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                      c + 2}Ready == 0) {\n                      xTexelC${c + 2} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= ${xNumCols}) {\n                        xTexelC${c + 2}.zw = vec2(0.0);\n                      }\n                      xTexelC${c + 2}Ready = 1;\n                    }\n\n                    xC${colIndex + 1} = xTexelC${c + 2};\n                    `;\n                }\n              }\n            }\n          }\n        } else {  // stride === 2\n          if (c < filterWidth) {\n            // Depending on whether padLeft is even or odd, we want either the\n            // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n            // even, xC${colIndex +1} is simply the zw channels of texels we've\n            // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n            // need to come from the xy channels of a new texel, hence the `\n            // vec4\n            // final` initialized below.\n            if (padLeft % 2 === 1) {\n              mainLoop += `\n                xCOffset = xC + 1 - ${strideWidth};\n                if(xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                  c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < ${xNumCols} && xTexelC${\n                  c + 2}Ready == 0) {\n                  xTexelC${c + 2} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= ${xNumCols}) {\n                    xTexelC${c + 2}.zw = vec2(0.0);\n                  }\n                  xTexelC${c + 2}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(xTexelC${c}.zw, xTexelC${c + 2}.zw);\n              `;\n\n              if (c + 1 < filterWidth) {\n                mainLoop += `\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + ${strideWidth};\n                  if(xCOffset >= 0 && xCOffset < ${xNumCols}) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${colIndex + 1} = vec4(xTexelC${c + 2}.xy, final.xy);\n                `;\n              }\n            } else {\n              mainLoop += `\n                if(xC >= 0 && xC < ${xNumCols} && xTexelC${c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n\n                xCOffset = xC + ${strideWidth};\n                if(xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${\n                  c + 2}Ready == 0) {\n                  xTexelC${c + 2} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= ${xNumCols}) {\n                    xTexelC${c + 2}.zw = vec2(0.);\n                  }\n                  xTexelC${c + 2}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(\n                  xTexelC${c}.xy, xTexelC${c + 2}.xy);\n              `;\n\n              if (c + 1 < filterWidth) {\n                mainLoop += `\n                  xC${colIndex + 1} = vec4(xTexelC${c}.zw, xTexelC${c + 2}.zw);\n                `;\n              }\n            }\n          }\n        }\n\n        // localize the dotProd accumulation within the loop, the theory is for\n        // GPU with limited cache, accumulate sum across large amount of\n        // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n        // 50 variables)\n        if (colIndex < filterWidth) {\n          mainLoop += `\n            wTexel = getW(${r}, ${c}, d1, q);\n            dotProd += xC${colIndex} * vec4(wTexel.xz, wTexel.xz);\n          `;\n\n          if (c + 1 < filterWidth) {\n            mainLoop += `\n              wTexel = getW(${r}, ${c + 1}, d1, q);\n              dotProd += xC${colIndex + 1} * vec4(wTexel.xz, wTexel.xz);\n            `;\n          }\n        }\n      }\n      mainLoop += `\n        }\n      `;\n    }\n\n    let activationSnippet = '', applyActivationSnippet = '';\n    if (activation) {\n      if (hasPreluActivation) {\n        activationSnippet = `vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`;\n      } else if (hasLeakyReluAlpha) {\n        activationSnippet = `vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`;\n      } else {\n        activationSnippet = `vec4 activation(vec4 x) {\n          ${activation}\n        }`;\n      }\n\n      applyActivationSnippet = `result = activation(result);`;\n    }\n\n    const addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n    if (hasLeakyReluAlpha) {\n      this.variableNames.push('leakyreluAlpha');\n    }\n\n    this.userCode = `\n      ${activationSnippet}\n\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${channelMul};\n        int q = d2 - d1 * ${channelMul};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${mainLoop}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `;\n  }\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}